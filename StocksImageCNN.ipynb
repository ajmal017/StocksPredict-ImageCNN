{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = yf.Ticker(\"RELIANCE.NS\")\n",
    "data = ticker.history(\n",
    "    # period = \"20y\",\n",
    "    start = '2002-01-01',\n",
    "    end = '2019-12-31',\n",
    "    interval = \"1d\")\n",
    "\n",
    "data.sort_values('Date', inplace=True, ascending=True)\n",
    "# data.reset_index(inplace = True)\n",
    "data = data[data['Volume']>0] #To filter out garbage values\n",
    "data.drop(['Dividends', 'Stock Splits'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "data['Change'] = 100*((data['Close']-data['Close'].shift(1))/data['Close'].shift(1))\n",
    "data['Signal'] = 2\n",
    "data['Signal'] = np.where(data['Change']>= 1, 3, data['Signal'])\n",
    "data['Signal'] = np.where(data['Change']>= 2.5, 4, data['Signal'])\n",
    "data['Signal'] = np.where(data['Change']<=-1, 1, data['Signal'])\n",
    "data['Signal'] = np.where(data['Change']<=-2.5, 0, data['Signal'])\n",
    "data = data[1:] # Drop first row because NAN\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createImage(df, height_multiplier, min_val, max_val):\n",
    "    image_width = len(df)\n",
    "    image_height = height_multiplier*image_width\n",
    "    image = np.zeros((image_height, image_width))\n",
    "    factor = image_height/(max_val-min_val)\n",
    "    for i in range(len(df)):\n",
    "        if(df.Open.iloc[i]<=df.Close.iloc[i]):\n",
    "            candle_width = max(int((df.Close.iloc[i] - df.Open.iloc[i])*factor),1)\n",
    "            start = int((max_val - df.Close.iloc[i])*factor)\n",
    "            image[start:start+candle_width,i] = 128\n",
    "        else:\n",
    "            candle_width = max(int((df.Open.iloc[i] - df.Close.iloc[i])*factor),1)\n",
    "            start = int((max_val - df.Open.iloc[i])*factor)\n",
    "            image[start:start+candle_width,i] = 255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataGenerator(df, timestep, window, height_multiplier=5, batch_size=16):\n",
    "    c = 0\n",
    "    while(True):\n",
    "        image_width = timestep\n",
    "        image_height = height_multiplier*image_width\n",
    "\n",
    "        img = np.zeros((batch_size, image_height, image_width, 1)).astype('float')\n",
    "        y = np.zeros((batch_size))\n",
    "\n",
    "        for i in range(c, c+batch_size):\n",
    "            # Create slice of dataframe and Retrieve image\n",
    "            data = df[window+i:window+i+timestep]\n",
    "            max_val = df[i:window+i+timestep].High.max()\n",
    "            min_val = df[i:window+i+timestep].Low.min()\n",
    "            image = createImage(data, height_multiplier, min_val, max_val)\n",
    "\n",
    "            # Get prediction\n",
    "            pred = df.Signal.iloc[window+i+timestep]\n",
    "\n",
    "            # Add to respective batch sized arrays\n",
    "            image = image.reshape(image.shape[0], image.shape[1], 1)\n",
    "            img[i-c] = image\n",
    "            y[i-c] = pred\n",
    "\n",
    "        c+=batch_size\n",
    "        if(c + batch_size+window+timestep >= len(df)):\n",
    "            c=0\n",
    "        yield img, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  layers.Conv2D(8, 3, padding='same', activation='relu', input_shape=(int(timestep*height_multiplier), timestep, 1)),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "timestep = 50\n",
    "height_multiplier = 2\n",
    "window = int(timestep*1)\n",
    "\n",
    "split_test = int(len(data)*0.95)\n",
    "split_val = int(len(data)*0.85)\n",
    "\n",
    "train_gen = dataGenerator(data[:split_val], timestep, window, height_multiplier, batch_size)\n",
    "val_gen = dataGenerator(data[split_val:split_test], timestep, window, height_multiplier, batch_size)\n",
    "test_gen = dataGenerator(data[split_test:], timestep, window, height_multiplier, batch_size)\n",
    "\n",
    "history = model.fit(x=train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    epochs=15,\n",
    "                    steps_per_epoch = split_val // batch_size,\n",
    "                    validation_steps = (split_test-split_val) // batch_size,\n",
    "                    shuffle=False,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(test_gen, steps = (len(data)-split_test)//batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
